# AnyText2 LCM Training "backward through the graph a second time" é”™è¯¯æ·±åº¦åˆ†æ

## é”™è¯¯è¡¨ç°
```
RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors
after they have already been freed). Saved intermediate values of the graph are freed when you
call .backward() or autograd.grad().
```

**å…³é”®ç‰¹å¾**ï¼š
- é”™è¯¯å‘ç”Ÿåœ¨**ç¬¬ä¸€æ¬¡ backward** æ—¶ï¼ˆä¸æ˜¯ç¬¬äºŒæ¬¡ï¼‰
- ä½¿ç”¨äº† LoRA + Accelerate + AnyText2 ControlNet
- å·²ç»å°è¯•è¿‡ï¼šæ‰‹åŠ¨æ¢¯åº¦ç´¯ç§¯ã€é€’å½’ detachã€retain_graph=False

---

## 1. AnyText2ForwardWrapper å®Œæ•´å®ç°åˆ†æ

### æºä»£ç 
```python
class AnyText2ForwardWrapper:
    """
    Wrapper to simplify AnyText2 forward pass for LCM training.
    """

    def __init__(self, model: ControlLDM, device: torch.device):
        self.model = model
        self.model.to(device)
        self.device = device

    def encode_text(self, batch: dict, text_info: dict = None) -> dict:
        """Encode text captions using CLIP encoder."""
        cond = {
            'c_crossattn': [[batch['img_caption'], batch['text_caption']]],
            'text_info': text_info
        }

        with torch.no_grad():
            c = self.model.get_learned_conditioning(cond)

        return c

    def prepare_text_info(self, batch: dict) -> dict:
        """Prepare text_info dict for AnyText2 forward."""
        text_info = {
            'glyphs': batch['glyphs'],
            'positions': batch['positions'],
            'colors': batch['color'],
            'n_lines': batch['n_lines'],
            'language': batch['language'],
            'texts': batch['texts'],
            'img': batch['img'],  # (B, H, W, 3) NHWC
            'masked_x': batch['masked_x'],
            'gly_line': batch['gly_line'],
            'inv_mask': batch['inv_mask'],
            'font_hint': batch['font_hint'],
        }
        return text_info

    def forward(
        self,
        latents: torch.Tensor,
        t: torch.Tensor,
        text_emb: dict,
        text_info: dict,
        hint: torch.Tensor
    ) -> torch.Tensor:
        """Forward pass through AnyText2 model."""
        cond = {
            'c_concat': [hint],
            'c_crossattn': text_emb['c_crossattn'],
            'text_info': text_info
        }

        noise_pred = self.model.apply_model(latents, t, cond)

        return noise_pred
```

### ğŸ” å…³é”®å‘ç°
âœ… **Wrapper æœ¬èº«æ˜¯æ— çŠ¶æ€çš„**ï¼š
- æ²¡æœ‰åœ¨ `self` ä¸Šå­˜å‚¨ä»»ä½• tensor
- æ‰€æœ‰è¿”å›å€¼éƒ½æ˜¯æ–°ç”Ÿæˆçš„å¯¹è±¡
- `encode_text` ä½¿ç”¨äº† `torch.no_grad()`

âš ï¸ **ä½†æ˜¯**ï¼š
- `text_info` å­—å…¸åŒ…å«äº†**å¤§é‡åµŒå¥—çš„ tensor**ï¼ˆglyphs, positions, masked_x ç­‰ï¼‰
- è¿™äº› tensor æ¥è‡ª batchï¼Œå¯èƒ½åœ¨æŸäº›æƒ…å†µä¸‹ä¿ç•™æ¢¯åº¦è¿æ¥

---

## 2. ControlLDM.apply_model æºç åˆ†æ

### æºä»£ç ï¼ˆ`cldm/cldm.py:513-553`ï¼‰
```python
def apply_model(self, x_noisy, t, cond, *args, **kwargs):
    assert isinstance(cond, dict)
    diffusion_model = self.model.diffusion_model
    img_cond = cond['c_crossattn'][0][0]
    text_cond = cond['c_crossattn'][0][1]
    _hint = torch.cat(cond['c_concat'], 1)

    if self.use_fp16:
        x_noisy = x_noisy.half()

    if text_cond is None:
        control = None  # uncond
    else:
        # âš ï¸ å…³é”®éƒ¨åˆ†ï¼šæ§åˆ¶ä¿¡å·ç¼“å­˜æœºåˆ¶
        if self.control is None or self.control_uncond is None or not self.control_model.fast_control:
            _control = self.control_model(
                x=x_noisy,
                timesteps=t,
                context=text_cond,
                hint=_hint,
                text_info=cond['text_info']
            )
            if not text_cond.requires_grad and self.control is not None and self.control_uncond is None:
                self.control_uncond = _control  # âš ï¸ ç¼“å­˜åˆ° self
            else:
                self.control = _control  # âš ï¸ ç¼“å­˜åˆ° self

        # æ ¹æ® requires_grad å†³å®šä½¿ç”¨å“ªä¸ªç¼“å­˜
        if not text_cond.requires_grad:
            if self.is_uncond:
                control = [c.clone() for c in self.control_uncond]
                self.is_uncond = False
            else:
                control = [c.clone() for c in self.control]
                self.is_uncond = True
        else:
            control = [c.clone() for c in self.control]

    control = [c * scale for c, scale in zip(control, self.control_scales[:len(control)])]

    eps = diffusion_model(
        x=x_noisy,
        timesteps=t,
        context=img_cond,
        control=control,
        only_mid_control=self.only_mid_control,
        attnx_scale=self.attnx_scale
    )

    return eps
```

### ğŸš¨ **å‘ç°é‡å¤§é—®é¢˜ï¼**

**é—®é¢˜æ ¹æºï¼šControlNet çš„æ§åˆ¶ä¿¡å·ç¼“å­˜æœºåˆ¶**

1. **Teacher forward (uncond)**ï¼š
   - `text_cond` æ˜¯æ™®é€šçš„ tensorï¼ˆä» CLIP encoder æ¥ï¼‰
   - `text_cond.requires_grad = False`
   - ä»£ç æ‰§è¡Œï¼š`self.control_uncond = _control`ï¼ˆç¬¬527è¡Œï¼‰
   - **å…³é”®**ï¼šè¿™ä¸ª `_control` æ˜¯ ControlNet çš„è¾“å‡ºï¼Œ**è™½ç„¶ç”¨ no_grad åŒ…è£¹ï¼Œä½†å¦‚æœ input tensor æœ‰æ¢¯åº¦å†å²ï¼Œoutput ä¹Ÿå¯èƒ½ä¿ç•™**

2. **Teacher forward (cond)**ï¼š
   - åŒæ · `text_cond.requires_grad = False`
   - ä»£ç æ‰§è¡Œï¼š`self.control = _control`ï¼ˆç¬¬529è¡Œï¼‰

3. **Student forward (cond, with grad)**ï¼š
   - `text_cond` ä»ç„¶æ˜¯ä» teacher encoder æ¥çš„ï¼Œ`requires_grad = False`
   - ä»£ç è¿›å…¥ `if not text_cond.requires_grad:` åˆ†æ”¯ï¼ˆç¬¬530è¡Œï¼‰
   - ä½¿ç”¨ `[c.clone() for c in self.control]`ï¼ˆç¬¬538è¡Œï¼‰
   - **âš ï¸ é—®é¢˜**ï¼šè™½ç„¶ clone äº†ï¼Œä½†å¦‚æœ `self.control` å†…éƒ¨çš„æŸä¸ª tensor ä»ç„¶è¿æ¥ç€ teacher çš„è®¡ç®—å›¾ï¼Œclone ä¼šä¿ç•™è¿™ä¸ªè¿æ¥ï¼

4. **ç¬¬äºŒæ¬¡ batch çš„ Teacher forward**ï¼š
   - å°è¯•æ›´æ–° `self.control = _control`
   - ä½†æ­¤æ—¶ `self.control` å¯èƒ½ä»ç„¶è¿æ¥ç€ä¸Šæ¬¡ student çš„è®¡ç®—å›¾
   - **ğŸ’¥ çˆ†ç‚¸**ï¼šPyTorch æ£€æµ‹åˆ°è¯•å›¾é€šè¿‡å·²ç»è¢«é‡Šæ”¾çš„è®¡ç®—å›¾è¿›è¡Œ backward

### éªŒè¯è¿™ä¸ªå‡è®¾çš„è¯æ®

**ä»£ç ä¸­çš„å…³é”®çº¿ç´¢**ï¼š
```python
# Line 524-529: ç¼“å­˜é€»è¾‘
if self.control is None or self.control_uncond is None or not self.control_model.fast_control:
    _control = self.control_model(...)
    if not text_cond.requires_grad and self.control is not None and self.control_uncond is None:
        self.control_uncond = _control  # âš ï¸ ç¬¬ä¸€æ¬¡ï¼šç¼“å­˜ uncond
    else:
        self.control = _control  # âš ï¸ ç¬¬äºŒæ¬¡ï¼šç¼“å­˜ cond
```

**æ—¶åºåˆ†æ**ï¼š
1. Teacher forward (uncond) â†’ `self.control_uncond = _control`
2. Teacher forward (cond) â†’ `self.control = _control`
3. Student forward (cond) â†’ ä½¿ç”¨ `self.control`ï¼Œä½†å¯èƒ½ä¿ç•™æ¢¯åº¦
4. **ä¸‹ä¸€ä¸ª batch** â†’ Teacher forward å°è¯•æ›´æ–° `self.control` â†’ å‘ç°æ—§çš„ `self.control` è¿˜è¿æ¥ç€ student çš„å›¾ â†’ æŠ¥é”™ï¼

---

## 3. LoRA æ³¨å…¥åçš„æ¨¡å‹ç»“æ„åˆ†æ

### å¾…æä¾›çš„è„šæœ¬è¾“å‡º
ç”±äºç¯å¢ƒé™åˆ¶ï¼Œæˆ‘å°†åœ¨ç”¨æˆ·è¿è¡Œåè¡¥å……è¿™éƒ¨åˆ†ä¿¡æ¯ã€‚

**éœ€è¦å…³æ³¨çš„é—®é¢˜**ï¼š
- ControlNet å’Œ UNet æ˜¯å¦å…±äº«åŸºç¡€æƒé‡ï¼Ÿ
- PEFT çš„ LoRA æ˜¯å¦æ­£ç¡®æ³¨å…¥åˆ° ControlNet çš„ zero_convï¼Ÿ
- æ˜¯å¦å­˜åœ¨åŒé‡æ³¨å…¥ï¼ˆåŒä¸€å±‚è¢«æ³¨å…¥ä¸¤æ¬¡ï¼‰ï¼Ÿ

---

## 4. å½“å‰ä»£ç çŠ¶æ€

### training_step å‡½æ•°ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
```python
def detach_recursive(obj):
    """é€’å½’ detach å’Œ clone"""
    if isinstance(obj, torch.Tensor):
        return obj.detach().clone()
    elif isinstance(obj, dict):
        return {k: detach_recursive(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [detach_recursive(v) for v in obj]
    elif isinstance(obj, tuple):
        return tuple(detach_recursive(v) for v in obj)
    else:
        return obj

def training_step(...):
    # A. Teacher Phase (NO GRAD)
    with torch.no_grad():
        # ... æ‰€æœ‰ teacher è®¡ç®—
        target_x0 = scheduler.predict_x0(...)

    # B. The Firewall: Recursive Detach
    student_inputs = {
        'noisy_latents': detach_recursive(noisy_latents),
        't': detach_recursive(t),
        'cond_text_emb': detach_recursive(cond_text_emb),  # é€’å½’åˆ‡æ–­
        'cond_text_info': detach_recursive(cond_text_info),  # é€’å½’åˆ‡æ–­
        'hint': detach_recursive(cond_hint),
        'target_x0': detach_recursive(target_x0)
    }

    # C. Student Phase (ENABLE GRAD)
    with torch.set_grad_enabled(True):
        noise_pred_student = student_wrapper.forward(
            student_inputs['noisy_latents'],
            student_inputs['t'],
            student_inputs['cond_text_emb'],
            student_inputs['cond_text_info'],
            student_inputs['hint']
        )
        # ...
```

### main å¾ªç¯ï¼ˆå½“å‰ç‰ˆæœ¬ï¼‰
```python
# æ‰‹åŠ¨æ¢¯åº¦ç´¯ç§¯
optimizer.zero_grad()

for epoch in range(100):
    for batch in dataloader:
        outputs = training_step(...)

        loss = outputs['loss']
        loss_scaled = loss / args.gradient_accumulation_steps

        accelerator.backward(loss_scaled, retain_graph=False)

        total_batch_steps += 1

        if total_batch_steps % args.gradient_accumulation_steps == 0:
            if accelerator.sync_gradients:
                accelerator.clip_grad_norm_(student.parameters(), 1.0)

            optimizer.step()
            optimizer.zero_grad(set_to_none=True)

            global_step += 1
            # logging...

        del outputs, loss, loss_scaled
```

---

## ğŸ”¥ é—®é¢˜ç¡®è¯Šï¼šControlNet çš„ `self.control` ç¼“å­˜æ±¡æŸ“

### æ ¹æœ¬åŸå› 
**AnyText2 çš„ ControlLDM.apply_model ä¸­ä½¿ç”¨äº† `self.control` å’Œ `self.control_uncond` æ¥ç¼“å­˜ ControlNet çš„è¾“å‡ºã€‚**

**é—®é¢˜é“¾æ¡**ï¼š
1. Teacher forward æ—¶è®¡ç®—å¹¶ç¼“å­˜ `self.control`
2. Student forward æ—¶ä½¿ç”¨ `self.control`ï¼ˆè™½ç„¶ clone äº†ï¼‰
3. Student backward æ—¶ï¼Œæ¢¯åº¦å¯èƒ½ä¼ æ’­åˆ° `self.control` çš„**å†…éƒ¨ tensor**
4. ä¸‹ä¸€ä¸ª batch çš„ teacher forward å°è¯•æ›´æ–° `self.control`
5. PyTorch å‘ç° `self.control` çš„æŸäº› tensor ä»ç„¶è¿æ¥ç€ä¸Šæ¬¡çš„è®¡ç®—å›¾ â†’ **æŠ¥é”™ï¼**

### ä¸ºä»€ä¹ˆä¹‹å‰çš„ä¿®å¤æ²¡æœ‰ç”Ÿæ•ˆ

1. **Detach inputs**ï¼šåˆ‡æ–­äº†è¾“å…¥çš„æ¢¯åº¦ï¼Œä½† `self.control` æ˜¯ model å†…éƒ¨çš„çŠ¶æ€
2. **Recursive detach**ï¼šåˆ‡æ–­äº†ä¼ å…¥ student çš„æ•°æ®ï¼Œä½† student çš„ forward å¯èƒ½ä¿®æ”¹äº† `self.control`
3. **retain_graph=False**ï¼šåªæ˜¯ä¸ä¿ç•™å›¾ï¼Œä½† `self.control` ä»ç„¶å¼•ç”¨ç€æ—§çš„ tensor

### éªŒè¯å‡è®¾çš„å…³é”®è¯æ®

ä» `cldm/cldm.py:530-538` å¯ä»¥çœ‹åˆ°ï¼š
```python
if not text_cond.requires_grad:
    if self.is_uncond:
        control = [c.clone() for c in self.control_uncond]
        self.is_uncond = False
    else:
        control = [c.clone() for c in self.control]  # âš ï¸ ä½¿ç”¨ç¼“å­˜çš„ control
        self.is_uncond = True
else:
    control = [c.clone() for c in self.control]
```

**æ—¶åºé—®é¢˜**ï¼š
- Teacher: `self.is_uncond` åœ¨ True/False ä¹‹é—´åˆ‡æ¢
- Student: æ€»æ˜¯ä½¿ç”¨ `self.control`ï¼ˆå› ä¸º text_cond.requires_grad=Falseï¼‰
- **Batch 1**: Teacher â†’ Student (æ›´æ–° self.control çš„æ¢¯åº¦å†å²)
- **Batch 2**: Teacher å°è¯•è¦†ç›– self.control â†’ å‘ç°å®ƒè¿æ¥ç€ Batch 1 çš„å›¾ â†’ é”™è¯¯

---

## ğŸ’¡ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1ï¼šå¼ºåˆ¶ç¦ç”¨ ControlNet ç¼“å­˜ï¼ˆæ¨èï¼‰

åœ¨ training_step ä¸­ï¼Œæ¯æ¬¡ forward å‰**é‡ç½®** control ç¼“å­˜ï¼š

```python
def training_step(...):
    # ... teacher phase ...

    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶åˆ·æ–° control ç¼“å­˜
    teacher_wrapper.model.control = None
    teacher_wrapper.model.control_uncond = None

    # Firewall: detach all inputs
    student_inputs = {...}

    # Student phase
    with torch.set_grad_enabled(True):
        # å†æ¬¡ç¡®ä¿ç¼“å­˜è¢«æ¸…ç©º
        student_wrapper.model.control = None
        student_wrapper.model.control_uncond = None

        noise_pred_student = student_wrapper.forward(...)
```

### æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ç‹¬ç«‹çš„ student control_model

ä¿®æ”¹ student æ¨¡å‹ï¼Œä½¿å…¶æ‹¥æœ‰ç‹¬ç«‹çš„ control_model å®ä¾‹ï¼Œé¿å…å…±äº«ã€‚

### æ–¹æ¡ˆ 3ï¼šä¿®æ”¹ apply_model çš„ç¼“å­˜é€»è¾‘ï¼ˆä¾µå…¥æ€§ï¼‰

ä¿®æ”¹ AnyText2 æºç ï¼Œåœ¨æ£€æµ‹åˆ° `requires_grad=True` æ—¶ï¼Œä¸ä½¿ç”¨ç¼“å­˜ã€‚

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³æµ‹è¯•æ–¹æ¡ˆ 1**ï¼šæ·»åŠ  `model.control = None` é‡ç½®
2. **è§‚å¯Ÿç»“æœ**ï¼šå¦‚æœä»ç„¶æŠ¥é”™ï¼Œåˆ™éœ€è¦æ·±å…¥åˆ†æ LoRA æ³¨å…¥
3. **æä¾› LoRA ç»“æ„ä¿¡æ¯**ï¼šè¿è¡Œè„šæœ¬å¹¶æä¾›æ¨¡å‹ç»“æ„
4. **æœ€ç»ˆä¿®å¤**ï¼šæ ¹æ®æµ‹è¯•ç»“æœç¡®å®šæœ€ç»ˆæ–¹æ¡ˆ

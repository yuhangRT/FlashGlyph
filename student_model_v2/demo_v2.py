'''
AnyText2: Visual Text Generation and Editing With Customizable Attributes
Paper: https://arxiv.org/abs/2411.15245
Code: https://github.com/tyxsspa/AnyText2
Copyright (c) Alibaba, Inc. and its affiliates.
'''
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'
import cv2
import gradio as gr
import numpy as np
import argparse
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from util import check_channels, resize_image, save_images
from PIL import ImageColor
from student_model_v2.ms_wrapper_v2 import AnyText2StudentModel


img_save_folder = 'SaveImages'
load_model = True

font_path = {
    "Arial_Unicode": "font/lang_font/Arial_Unicode.ttf",
    "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·": "font/lang_font/é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·.otf",
    "ä»¿ä¹¾éš†å­—ä½“": "font/lang_font/ä»¿ä¹¾éš†å­—ä½“.ttf",
    "é’‰é’‰è¿›æ­¥ä½“": "font/lang_font/é’‰é’‰è¿›æ­¥ä½“.ttf",
    "æ·˜å®ä¹°èœè¥é”€ä½“": "font/lang_font/æ·˜å®ä¹°èœè¥é”€ä½“.otf",
    "ç«™é…·å¿«ä¹ä½“2016ä¿®è®¢ç‰ˆ": "font/lang_font/ç«™é…·å¿«ä¹ä½“2016ä¿®è®¢ç‰ˆ.ttf",
    "ç«™é…·åº†ç§‘é»„æ²¹ä½“": "font/lang_font/ç«™é…·åº†ç§‘é»„æ²¹ä½“.ttf",
    "ç«™é…·å°è–‡LOGOä½“": "font/lang_font/ç«™é…·å°è–‡LOGOä½“.otf",
    "BadScript": "font/lang_font/BadScript-Regular.ttf",
    "BodoniModa": "font/lang_font/BodoniModa-Italic-VariableFont_opsz,wght.ttf",
    "IndieFlower": "font/lang_font/IndieFlower-Regular.ttf",
    "Jaini": "font/lang_font/Jaini-Regular.ttf",
    "LongCang": "font/lang_font/LongCang-Regular.ttf",
    "Pacifico": "font/lang_font/Pacifico-Regular.ttf",
    "PlayfairDisplay": "font/lang_font/PlayfairDisplay-VariableFont_wght.ttf",
    "SourceHanSansCN": "font/lang_font/SourceHanSansCN-Medium.otf",
}


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--use_fp32",
        action="store_true",
        default=False,
        help="Whether or not to use fp32 during inference."
    )
    parser.add_argument(
        "--no_translator",
        action="store_true",
        default=False,
        help="Whether or not to use the CH->EN translator, which enable input Chinese prompt and cause ~4GB VRAM."
    )
    parser.add_argument(
        "--font_path",
        type=str,
        default='font/Arial_Unicode.ttf',
        help="path of a font file"
    )
    parser.add_argument(
        "--model_dir",
        type=str,
        default='./models/iic/cv_anytext2',
        help="directory that contains AnyText2 assets (clip, translator)"
    )
    parser.add_argument(
        "--model_path",
        type=str,
        default='models/anytext_v2.0.ckpt',
        help="load a specified anytext checkpoint"
    )
    parser.add_argument(
        "--student_lora_path",
        type=str,
        default='student_model_v2/checkpoints/checkpoint-final',
        help="path to the student LoRA adapter"
    )
    parser.add_argument(
        "--use_ddim_sampler",
        action="store_true",
        default=False,
        help="use original DDIM sampler instead of LCM sampler"
    )
    args = parser.parse_args()
    return args


args = parse_args()
infer_params = {
    "use_fp16": not args.use_fp32,
    "use_translator": not args.no_translator,
    "font_path": args.font_path,
    "student_lora_path": args.student_lora_path,
    "use_lcm_sampler": not args.use_ddim_sampler,
}
if args.model_path:
    infer_params['model_path'] = args.model_path
if load_model:
    inference = AnyText2StudentModel(model_dir=args.model_dir, **infer_params).cuda(0)


def process(mode, img_prompt, text_prompt, sort_radio, revise_pos, base_model_path, lora_path_ratio, f1, f2, f3, f4, f5, m1, m2, m3, m4, m5, c1, c2, c3, c4, c5, show_debug, draw_img, ref_img, ori_img, img_count, ddim_steps, w, h, strength, attnx_scale, font_hollow, cfg_scale, seed, eta, a_prompt, n_prompt):
    skip_uncond = getattr(inference, "use_lcm_sampler", False)
    if skip_uncond:
        if ddim_steps < 4:
            ddim_steps = 4
        elif ddim_steps > 8:
            ddim_steps = 8
        cfg_scale = 1.0

    select_font_list = [f1, f2, f3, f4, f5]
    select_color_list = [c1, c2, c3, c4, c5]
    mimic_list = [m1, m2, m3, m4, m5]

    font_hint_image = [None] * 5
    font_hint_mask = [None] * 5
    glyline_font_path = ['None'] * 5
    text_colors = ' '.join(['500,500,500']*5)
    for idx, f in enumerate(select_font_list):
        if f is None or f == 'No Font(ä¸æŒ‡å®šå­—ä½“)':
            pass
        elif f == 'Mimic From Image(æ¨¡ä»¿å›¾ä¸­å­—ä½“)':
            img = mimic_list[idx]
            if 'layers' in img and img['layers'][0][..., 3:].mean() > 0:
                font_hint_image[idx] = img['background'][..., :3][..., ::-1]
                font_hint_mask[idx] = img['layers'][0][..., 3:]
            else:
                font_hint_image[idx] = None
                font_hint_mask[idx] = None
        else:
            try:
                glyline_font_path[idx] = font_path[f]
            except KeyError:
                # If font not found in font_path dict, use default
                glyline_font_path[idx] = 'None'
    for idx, c in enumerate(select_color_list):
        if c is not None:
            strs = text_colors.split()
            if isinstance(c, str) and 'rgba' in c:
                rgb = [int(float(i)) for i in c.split('(')[-1].split(')')[0].split(',')[:3]]  # for gradio 5.X
            else:
                rgb = ImageColor.getcolor(c, "RGB")
            if list(rgb) == [0, 0, 0] or rgb == [255, 255, 255]:
                rgb = (500, 500, 500)
            rgb = ','.join([str(i) for i in list(rgb)])
            strs[idx] = rgb
            text_colors = ' '.join(strs)
    # Text Generation
    if mode == 'gen':
        # create pos_imgs
        if draw_img is not None:
            pos_imgs = 255 - draw_img['background'][..., :3]
            if 'layers' in draw_img and draw_img['layers'][0][..., :3].mean() > 0:
                if draw_img['layers'][0][..., 3].mean() != 255:
                    _pos = 255 - draw_img['layers'][0][..., 3:]
                else:
                    _pos = draw_img['layers'][0][..., :3]
                    _pos[_pos < 120] = 0
                pos_imgs = pos_imgs.astype(np.float32) + (255-_pos).astype(np.float32)
                pos_imgs = pos_imgs.clip(0, 255).astype(np.uint8)
        else:
            pos_imgs = np.zeros((w, h, 1))

    # Text Editing
    elif mode == 'edit':
        revise_pos = False  # disable pos revise in edit mode
        if ref_img is None or ori_img is None:
            raise gr.Error('No reference image, please upload one for edit!')
        edit_image = ori_img.clip(1, 255)  # for mask reason
        edit_image = check_channels(edit_image)
        edit_image = resize_image(edit_image, max_length=1024)
        h, w = edit_image.shape[:2]
        if isinstance(ref_img, dict) and 'layers' in ref_img and ref_img['layers'][0][..., 3:].mean() > 0:
            pos_imgs = 255 - edit_image
            edit_mask = cv2.resize(ref_img['layers'][0][..., 3:], (w, h))[..., None]
            pos_imgs = pos_imgs.astype(np.float32) + edit_mask.astype(np.float32)
            pos_imgs = pos_imgs.clip(0, 255).astype(np.uint8)
        else:
            if isinstance(ref_img, dict) and 'background' in ref_img:
                ref_img = ref_img['background'][..., :3]
            pos_imgs = 255 - ref_img  # example input ref_img is used as pos
    cv2.imwrite('pos_imgs.png', 255-pos_imgs[..., ::-1])
    params = {
        "mode": mode,
        "sort_priority": sort_radio,
        "show_debug": show_debug,
        "revise_pos": revise_pos,
        "image_count": img_count,
        "ddim_steps": ddim_steps,
        "image_width": w,
        "image_height": h,
        "strength": strength,
        "attnx_scale": attnx_scale,
        "font_hollow": font_hollow,
        "cfg_scale": cfg_scale,
        "skip_uncond": skip_uncond,
        "eta": eta,
        "a_prompt": a_prompt,
        "n_prompt": n_prompt,
        "base_model_path": base_model_path,
        "lora_path_ratio": lora_path_ratio,
        "glyline_font_path": glyline_font_path,
        "font_hint_image": font_hint_image,
        "font_hint_mask": font_hint_mask,
        "text_colors": text_colors
    }
    input_data = {
        "img_prompt": img_prompt,
        "text_prompt": text_prompt,
        "seed": seed,
        "draw_pos": pos_imgs,
        "ori_image": ori_img,
    }

    results, rtn_code, rtn_warning, debug_info = inference(input_data, **params)
    if rtn_code >= 0:
        save_images(results, img_save_folder)
        print(f'Done, result images are saved in: {img_save_folder}')
        if rtn_warning:
            gr.Warning(rtn_warning)
    else:
        raise gr.Error(rtn_warning)
    return results, gr.Markdown(debug_info, visible=show_debug)


def create_canvas(w=512, h=512, c=3, line=5):
    image = np.full((h, w, c), 200, dtype=np.uint8)
    for i in range(h):
        if i % (w//line) == 0:
            image[i, :, :] = 150
    for j in range(w):
        if j % (w//line) == 0:
            image[:, j, :] = 150
    image[h//2-8:h//2+8, w//2-8:w//2+8, :] = [200, 0, 0]
    # return image
    return {
        'background': image,
        "layers": [image],
        "composite": None
    }


def resize_w(w, img):
    if isinstance(img, dict):
        img = img['background']
    _img = cv2.resize(img, (w, img.shape[0]))
    return {
        'background': _img,
        "layers": [_img],
        "composite": None
    }


def resize_h(h, img):
    if isinstance(img, dict):
        img = img['background']
    _img = cv2.resize(img, (img.shape[1], h))
    return {
        'background': _img,
        "layers": [_img],
        "composite": None
    }


click_edit_exp = False
block = gr.Blocks(css='style.css', theme=gr.themes.Soft()).queue()


with block:
    gr.HTML('<div style="text-align: center; margin: 20px auto;"> \
            <img id="banner" src="https://modelscope.cn/api/v1/studio/iic/studio_anytext2/repo?Revision=master&FilePath=example_images%2Fbanner2.jpg&View=true" style="max-width:400px; width:100%; margin:auto; display:block;" alt="anytext2"> <br>  \
            [<a href="https://arxiv.org/abs/2411.15245" style="color:blue; font-size:18px;">arXiv</a>] \
            [<a href="https://github.com/tyxsspa/AnyText2" style="color:blue; font-size:18px;">Code</a>] \
            [<a href="https://modelscope.cn/studios/iic/studio_anytext2" style="color:blue; font-size:18px;">ModelScope</a>]\
            version: 1.0.0 </div>')
    with gr.Row(variant='compact'):
        with gr.Column(scale=3) as left_part:
            pass
        with gr.Column(scale=3):
            result_gallery = gr.Gallery(label='Result(ç»“æœ)', show_label=True, preview=True, columns=2, allow_preview=True, height=600)
            result_info = gr.Markdown('', visible=False)
        with left_part:
            with gr.Accordion('ğŸ› Parameters(å‚æ•°)', open=False):
                with gr.Row(variant='compact'):
                    img_count = gr.Slider(label="Image Count(å›¾ç‰‡æ•°)", minimum=1, maximum=12, value=4, step=1)
                    ddim_steps = gr.Slider(label="Steps(æ­¥æ•°)", minimum=1, maximum=100, value=6, step=1)
                with gr.Row(variant='compact'):
                    image_width = gr.Slider(label="Image Width(å®½åº¦)", minimum=256, maximum=1024, value=512, step=64)
                    image_height = gr.Slider(label="Image Height(é«˜åº¦)", minimum=256, maximum=1024, value=512, step=64)
                with gr.Row(variant='compact'):
                    strength = gr.Slider(label="Strength(æ§åˆ¶åŠ›åº¦)", minimum=0.0, maximum=2.0, value=1.0, step=0.01)
                    cfg_scale = gr.Slider(label="CFG-Scale(CFGå¼ºåº¦)", minimum=0.1, maximum=30.0, value=7.5, step=0.1)
                    attnx_scale = gr.Slider(label="Attnx_Scale(æ§åˆ¶åŠ›åº¦)", minimum=0.0, maximum=2.0, value=1.0, step=0.01)
                with gr.Row(variant='compact'):
                    seed = gr.Slider(label="Seed(ç§å­æ•°)", minimum=-1, maximum=99999999, step=1, randomize=False, value=-1)
                    eta = gr.Number(label="eta (DDIM)", value=0.0)
                with gr.Row(variant='compact'):
                    show_debug = gr.Checkbox(label='Show Debug(è°ƒè¯•ä¿¡æ¯)', value=True)
                    gr.Markdown('<span style="color:silver;font-size:12px">whether show glyph image and debug information in the result(æ˜¯å¦åœ¨ç»“æœä¸­æ˜¾ç¤ºglyphå›¾ä»¥åŠè°ƒè¯•ä¿¡æ¯)</span>')
                with gr.Row():
                    sort_radio = gr.Radio(["â†•", "â†”"], value='â†•', label="Sort Position(ä½ç½®æ’åº)", info="position sorting priority(ä½ç½®æ’åºæ—¶çš„ä¼˜å…ˆçº§)")
                    with gr.Row():
                        revise_pos = gr.Checkbox(label='Revise Position(ä¿®æ­£ä½ç½®)', value=False)
                        font_hollow = gr.Checkbox(label='Use hollow font(ä½¿ç”¨ç©ºå¿ƒå­—ä½“)', value=True)
                base_model_path = gr.Textbox(label='Base Model Path(åŸºæ¨¡åœ°å€)', placeholder='/path/of/base/model')
                lora_path_ratio = gr.Textbox(label='LoRA Path and Ratio(loraåœ°å€å’Œæ¯”ä¾‹)', placeholder='/path/of/lora1.pth ratio1 /path/of/lora2.pth ratio2 ...')
                a_prompt = gr.Textbox(label="Added Prompt(é™„åŠ æç¤ºè¯)", value='best quality, extremely detailed,4k, HD, supper legible text,  clear text edges,  clear strokes, neat writing, no watermarks')
                n_prompt = gr.Textbox(label="Negative Prompt(è´Ÿå‘æç¤ºè¯)", value='low-res, bad anatomy, extra digit, fewer digits, cropped, worst quality, low quality, watermark, unreadable text, messy words, distorted text, disorganized writing, advertising picture')
            img_prompt = gr.Textbox(label="Image Prompt(å›¾åƒæç¤ºè¯)", placeholder="Describe details for the image, e.g.: A cartoon cat holding a sign with words on it(è¯¦ç»†æè¿°ä½ è¦ç”Ÿæˆçš„å›¾ç‰‡ï¼Œå¦‚ï¼šä¸€åªå¡é€šé£æ ¼çš„å°çŒ«ä¸¾ç€ç‰Œå­ï¼Œä¸Šé¢å†™ç€æ–‡å­—)")
            text_prompt = gr.Textbox(label="Text Prompt(æ–‡å­—æç¤ºè¯)", placeholder='Write down the text, wrapping each line in double quotation marks, e.g.: that reads "Hello", "world!"(å†™ä¸‹ä½ è¦ç”Ÿæˆçš„æ–‡å­—ï¼Œæ¯è¡Œç”¨åŒå¼•å·åŒ…è£¹ï¼Œå¦‚ï¼šä¸Šé¢å†™ç€"ä½ å¥½", "ä¸–ç•Œ")')

            select_font_list = []
            mimic_list = []
            select_color_list = []

            font_values = ['No Font(ä¸æŒ‡å®šå­—ä½“)', 'Mimic From Image(æ¨¡ä»¿å›¾ä¸­å­—ä½“)'] + list(font_path.keys())
            gr.Markdown('<span style="color:silver;font-size:15px">Specify font and color of each line, random attributes will be applied if select No Font or pure black white colors.(æŒ‡å®šæ¯è¡Œæ–‡å­—çš„å­—ä½“å’Œé¢œè‰², ä¸æŒ‡å®šå­—ä½“æˆ–ä½¿ç”¨çº¯é»‘ç™½é¢œè‰²,åˆ™ä¼šä½¿ç”¨éšæœºå±æ€§)</span>')
            placeholder_mimic = "Upload an image and use the brush tool below to select the text area you want to mimic the font style from. It's best for that area to have the same number of characters.(ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ï¼Œç”¨ä¸‹æ–¹çš„ç¬”åˆ·å·¥å…·åœ¨å›¾ä¸­é€‰æ‹©ä½ è¦æ¨¡ä»¿å­—ä½“é£æ ¼çš„æ–‡å­—åŒºåŸŸ, è¯¥åŒºåŸŸæœ€å¥½å…·æœ‰ç›¸åŒæ•°é‡çš„å­—ç¬¦)"
            with gr.Column():
                with gr.Row():
                    gr.Markdown('### 1')
                    font1 = gr.Dropdown(font_values, label="Font(å­—ä½“)", interactive=True, scale=18, container=False)
                    color1 = gr.ColorPicker(label="Color(é¢œè‰²)", scale=16, container=False)
                mimic_font_img1 = gr.ImageMask(sources=['upload', 'clipboard'], placeholder=placeholder_mimic, transforms=(), layers=False, visible=False)
                with gr.Row():
                    gr.Markdown('### 2')
                    font2 = gr.Dropdown(font_values, label="Font(å­—ä½“)", interactive=True, scale=18, container=False)
                    color2 = gr.ColorPicker(label="Color(é¢œè‰²)", scale=16, container=False)
                mimic_font_img2 = gr.ImageMask(sources=['upload', 'clipboard'], placeholder=placeholder_mimic, transforms=(), layers=False, visible=False)
                with gr.Row():
                    gr.Markdown('### 3')
                    font3 = gr.Dropdown(font_values, label="Font(å­—ä½“)", interactive=True, scale=18, container=False)
                    color3 = gr.ColorPicker(label="Color(é¢œè‰²)", scale=16, container=False)
                mimic_font_img3 = gr.ImageMask(sources=['upload', 'clipboard'], placeholder=placeholder_mimic, transforms=(), layers=False, visible=False)
                with gr.Row():
                    gr.Markdown('### 4')
                    font4 = gr.Dropdown(font_values, label="Font(å­—ä½“)", interactive=True, scale=18, container=False)
                    color4 = gr.ColorPicker(label="Color(é¢œè‰²)", scale=16, container=False)
                mimic_font_img4 = gr.ImageMask(sources=['upload', 'clipboard'], placeholder=placeholder_mimic, transforms=(), layers=False, visible=False)
                with gr.Row():
                    gr.Markdown('### 5')
                    font5 = gr.Dropdown(font_values, label="Font(å­—ä½“)", interactive=True, scale=18, container=False)
                    color5 = gr.ColorPicker(label="Color(é¢œè‰²)", scale=16, container=False)
                mimic_font_img5 = gr.ImageMask(sources=['upload', 'clipboard'], placeholder=placeholder_mimic, transforms=(), layers=False, visible=False)

            def sel_font(font):
                vis = font == 'Mimic From Image(æ¨¡ä»¿å›¾ä¸­å­—ä½“)'
                return gr.ImageMask(visible=vis, interactive=True)

            font1.change(fn=sel_font, inputs=[font1], outputs=[mimic_font_img1])
            font2.change(fn=sel_font, inputs=[font2], outputs=[mimic_font_img2])
            font3.change(fn=sel_font, inputs=[font3], outputs=[mimic_font_img3])
            font4.change(fn=sel_font, inputs=[font4], outputs=[mimic_font_img4])
            font5.change(fn=sel_font, inputs=[font5], outputs=[mimic_font_img5])

            select_font_list = [font1, font2, font3, font4, font5]
            select_color_list = [color1, color2, color3, color4, color5]
            mimic_list = [mimic_font_img1, mimic_font_img2, mimic_font_img3, mimic_font_img4, mimic_font_img5]

            with gr.Tabs() as tab_modes:
                with gr.Tab("ğŸ–¼Text Generation(æ–‡å­—ç”Ÿæˆ)", elem_id='MD-tab-t2i') as mode_gen:
                    gr.Markdown('<span style="color:silver;font-size:15px">Use a brush to specify the position(s) of the text, the length should be resonable(ç”¨ç¬”åˆ·æŒ‡å®šæ¯è¡Œæ–‡å­—çš„ä½ç½®, é•¿åº¦è¦ä¸æ–‡å­—ä¸ªæ•°ä¿æŒåˆç†)</span>')
                    with gr.Row():
                        gr.Markdown("")
                        draw_img = gr.Sketchpad(value=create_canvas(), label="Draw Position(ç»˜åˆ¶ä½ç½®)", scale=3, visible=True, eraser=False, container=True, transforms=(), show_label=False, layers=False)
                        gr.Markdown("")

                    def re_draw():
                        return [gr.Sketchpad(value=create_canvas(), container=True, layers=False, scale=3, eraser=False, show_label=False), gr.Slider(value=512), gr.Slider(value=512)]
                    draw_img.clear(re_draw, None, [draw_img, image_width, image_height])
                    image_width.release(resize_w, [image_width, draw_img], [draw_img])
                    image_height.release(resize_h, [image_height, draw_img], [draw_img])

                    with gr.Row():
                        gr.Markdown("")
                        run_gen = gr.Button(value="Run(è¿è¡Œ)!", scale=3, elem_classes='run')
                        gr.Markdown("")

                    def exp_gen_click():
                        return [gr.Slider(value=512), gr.Slider(value=512)]  # all examples are 512x512, refresh draw_img
                    gr.Markdown('<span style="color:silver;font-size:15px">ğŸ‘‡ğŸ»ğŸ‘‡ğŸ»ğŸ‘‡ğŸ»Click an example and run! (ç‚¹å‡»ä»»ä¸€ç¤ºä¾‹, è¿è¡Œ!)</span>')
                    with gr.Tab("English Examples"):
                        exp_gen_en = gr.Examples(
                            [
                                ['photo of caramel macchiato coffee on the table, top-down perspective, with words written on it using cream', '"Any" "Text" "2"', "example_images/gen9.png", "â†”", False, 4, "IndieFlower", "IndieFlower", "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·", 'rgba(152, 58, 16, 1)', 'rgba(155, 61, 16, 1)', 'rgba(65, 18, 6,1)', 66273235],
                                ['A raccoon stands in front of the blackboard with words written on it', 'Texts are "Deep Learning"', "example_images/gen17.png", "â†•", False, 4, "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(215, 225, 224, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 7251085],
                                ['A crayon drawing by child,  a snowman with a Santa hat, pine trees, outdoors in heavy snowfall', 'titled "Snowman"', "example_images/gen18.png", "â†•", False, 4, "BadScript", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 35621187],
                                ['A fancy square birthday cake on the table, texts written in cream, close-up view, top-down perspective', 'Texts are â€œGenerated" "by" "AnyText2"', "example_images/cake.png", "â†•", False, 4, "Arial_Unicode", "IndieFlower", "BodoniModa", 'rgba(21, 254, 230, 1)', 'rgba(181, 185, 58, 1)', 'rgba(249, 100, 100,1)', 41799568],
                                ['A meticulously designed logo, a minimalist brain, stick drawing style, simplistic style,  refined with minimal strokes, black and white color, white background,  futuristic sense, exceptional design', 'logo name is "NextAI"', "example_images/gen19.png", "â†•", False, 4, "IndieFlower", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 23692115],
                                ['A fine sweater with knitted text', '"Have" "A" "Good Day"', "example_images/gen20.png", "â†•", False, 4, "SourceHanSansCN", "Jaini", "SourceHanSansCN", 'rgba(18, 49, 91, 1)', 'rgba(57, 177, 48, 1)', 'rgba(25, 54, 88,1)', 18752346],
                                ['Sign on the clean building with text on it', 'that reads "ç§‘å­¦" and "ê³¼í•™"  and "ã‚µã‚¤ã‚¨ãƒ³ã‚¹" and "SCIENCE"', "example_images/gen6.png", "â†•", False, 4, "Arial_Unicode", "Arial_Unicode", "Arial_Unicode", 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 'rgba(255, 255, 255,1)', 4498087],
                                ['A nice drawing in pencil of Michael Jackson,  with words written on it', '"Micheal" and "Jackson"', "example_images/gen7.png", "â†•", False, 4, "IndieFlower", "IndieFlower", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(39, 41, 33, 1)', 'rgba(41, 43, 35, 1)', 'rgba(0, 0, 0, 1)', 83866922],
                                ['a well crafted ice sculpture that made with text. Dslr photo, perfect illumination', '"Happy" and "Holidays"', "example_images/gen11.png", "â†•", False, 4, "Pacifico", "Pacifico", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(211, 220, 228, 1)', 'rgba(233, 237, 241, 1)', 'rgba(249, 100, 100,1)', 91944158],
                            ],
                            [img_prompt, text_prompt, draw_img, sort_radio, revise_pos, img_count, font1, font2, font3, color1, color2, color3, seed],
                            examples_per_page=5,
                            label=''
                        )
                        exp_gen_en.dataset.click(exp_gen_click, None, [image_width, image_height])
                    with gr.Tab("ä¸­æ–‡ç¤ºä¾‹"):
                        exp_gen_ch = gr.Examples(
                            [
                                ['ä¸€ä¸ªç²¾è‡´çš„ä¸­å›½ä¼ ç»Ÿæœˆé¥¼ï¼Œæ”¾åœ¨ç™½è‰²ç›˜å­é‡Œï¼Œæœˆé¥¼ä¸Šé¢æœ‰é›•åˆ»çš„æ–‡å­—å’ŒèŠ±æœµ', '"ä¸­ç§‹" "å›¢åœ†"', "example_images/yuebing.png", "â†•", False, 4, "Arial_Unicode", "ä»¿ä¹¾éš†å­—ä½“", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 40091080],
                                ['æœ¨æ¡Œä¸Šæ”¾ç€ä¸€å—ç»£ç€å­—çš„å¸ƒå’Œä¸€åªå¯çˆ±çš„å°è€è™ã€‚å¸ƒæ—è¾¹æœ‰ä¸€æ”¯ç‚¹ç‡ƒçš„èœ¡çƒ›ã€‚', '"æ™šå®‰" "Goodnight"', "example_images/tiger.png", "â†•", False, 4, "Arial_Unicode", "ç«™é…·å¿«ä¹ä½“2016ä¿®è®¢ç‰ˆ", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(222, 175, 0, 1)', 'rgba(0, 188, 175, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 86670233],
                                ['ä¸€åªæµ£ç†Šç«™åœ¨é»‘æ¿å‰', 'ä¸Šé¢å†™ç€"æ·±åº¦å­¦ä¹ "', "example_images/gen1.png", "â†•", False, 4, "LongCang", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(224, 215, 215, 1)', 'rgba(0, 0, 0,1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 81808278],
                                ['ä¸€ä¸ªç²¾ç¾çš„æ£’çƒå¸½æ”¾åœ¨æœ¨æ¡Œä¸Šï¼Œä¸Šé¢æœ‰é’ˆç»‡çš„æ–‡å­—', ' "ç”Ÿæˆå¼æ¨¡å‹"', "example_images/bangqiumao.png", "â†•", False, 4, "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 96425704],
                                ['ä¸€ä¸ªå„¿ç«¥èœ¡ç¬”ç”»ï¼Œæ£®æ—é‡Œæœ‰ä¸€ä¸ªå¯çˆ±çš„è˜‘è‡å½¢çŠ¶çš„æˆ¿å­', 'æ ‡é¢˜æ˜¯"æ£®æ—å°å±‹"', "example_images/gen16.png", "â†•", False, 4, "SourceHanSansCN", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 40173333],
                                ['ä¸€ä¸ªç²¾ç¾è®¾è®¡çš„logoï¼Œç”»çš„æ˜¯ä¸€ä¸ªé»‘ç™½é£æ ¼çš„å¨å¸ˆï¼Œå¸¦ç€å¨å¸ˆå¸½', 'logoä¸‹æ–¹å†™ç€â€œæ·±å¤œé£Ÿå ‚â€', "example_images/gen14.png", "â†•", False, 4, "ç«™é…·å¿«ä¹ä½“2016ä¿®è®¢ç‰ˆ", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 37000560],
                                ['ä¸€ä¸ªç²¾è‡´çš„é©¬å…‹æ¯ï¼Œä¸Šé¢é›•åˆ»ç€ä¸€é¦–ä¸­å›½å¤è¯—', 'å†…å®¹æ˜¯ "èŠ±è½çŸ¥å¤šå°‘" "å¤œæ¥é£é›¨å£°" "å¤„å¤„é—»å•¼é¸Ÿ" "æ˜¥çœ ä¸è§‰æ™“"', "example_images/gen3.png", "â†”", False, 4, "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·", "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·", "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·", "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·", 'rgba(131, 56, 31, 1)', 'rgba(132, 57, 34, 1)', 'rgba(134, 59, 37, 1)', 'rgba(136, 61, 39, 1)', 94328817],
                                ['ä¸€ä»¶ç²¾ç¾çš„æ¯›è¡£ï¼Œä¸Šé¢æœ‰é’ˆç»‡çš„æ–‡å­—', 'æ–‡å­—å†…å®¹æ˜¯: "å›¾æ–‡èåˆ"', "example_images/gen4.png", "â†•", False, 4, "Arial_Unicode", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(67, 225, 186, 1)', 'rgba(0, 0, 0,1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 48769450],
                                ['ä¸€ä¸ªåŒè‚©åŒ…æ”¾åœ¨æ¡Œå­ä¸Šï¼Œè¿‘æ™¯æ‹æ‘„ï¼Œä¸Šé¢æœ‰é’ˆç»‡çš„æ–‡å­—', 'â€ä¸ºäº†æ— æ³•â€œ â€è®¡ç®—çš„ä»·å€¼â€œ', "example_images/gen12.png", "â†•", False, 4, "æ·˜å®ä¹°èœè¥é”€ä½“", "ä»¿ä¹¾éš†å­—ä½“", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(255, 201, 26, 1)', 'rgba(0, 177, 255, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)', 49171567],
                                ['ä¸€ä¸ªæ¼‚äº®çš„èœ¡ç¬”ç”»ï¼Œæœ‰è¡Œæ˜Ÿï¼Œå®‡èˆªå‘˜ï¼Œè¿˜æœ‰å®‡å®™é£èˆ¹', 'ä¸Šé¢å†™çš„æ˜¯"å»ç«æ˜Ÿæ—…è¡Œ", "ç‹å°æ˜", "11æœˆ1æ—¥"', "example_images/gen5.png", "â†•", False, 4, "ä»¿ä¹¾éš†å­—ä½“", "ç«™é…·åº†ç§‘é»„æ²¹ä½“", "ç«™é…·åº†ç§‘é»„æ²¹ä½“", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(117, 117, 117, 1)', 'rgba(123, 152, 169, 1)', 'rgba(123, 152, 169, 1)', 'rgba(0, 0, 0,1)', 32608039],
                                ['ä¸€ä¸ªè£…é¥°åä¸½çš„è›‹ç³•ï¼Œä¸Šé¢ç”¨å¥¶æ²¹å†™ç€æ–‡å­—', 'â€œé˜¿é‡Œäº‘â€å’Œ"APSARA"', "example_images/gen13.png", "â†•", False, 4, "é˜¿é‡Œå¦ˆå¦ˆä¸œæ–¹å¤§æ¥·", "BodoniModa", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(0, 255, 147, 1)', 'rgba(246, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 98381182],
                                ['ä¸€æšä¸­å›½å¤ä»£é“œé’±', 'ä¸Šé¢çš„æ–‡å­—æ˜¯ "å›¾"  "æ–‡" "è" "åˆ"', "example_images/gen2.png", "â†•", False, 4, "ç«™é…·åº†ç§‘é»„æ²¹ä½“", "ç«™é…·åº†ç§‘é»„æ²¹ä½“", "ç«™é…·åº†ç§‘é»„æ²¹ä½“", "ç«™é…·åº†ç§‘é»„æ²¹ä½“", 'rgba(208, 196, 152, 1)', 'rgba(221, 212, 165,1)', 'rgba(220, 213, 166, 1)', 'rgba(220, 214, 167,1)', 20842124],
                            ],
                            [img_prompt, text_prompt, draw_img, sort_radio, revise_pos, img_count, font1, font2, font3, font4, color1, color2, color3, color4, seed],
                            examples_per_page=5,
                            label=''
                        )
                        exp_gen_ch.dataset.click(exp_gen_click, None, [image_width, image_height])

                with gr.Tab("ğŸ¨Text Editing(æ–‡å­—ç¼–è¾‘)") as mode_edit:
                    gr.Markdown('<span style="color:silver;font-size:15px">Tips: Mimic specific font from original image may provide better results.(æç¤º: ä»åŸå§‹å›¾åƒä¸­çš„ç‰¹å®šåŒºåŸŸæ¨¡ä»¿å­—ä½“é£æ ¼, å¯æä¾›æ›´å¥½çš„ç¼–è¾‘æ•ˆæœ)</span>')
                    with gr.Row(variant='compact'):
                        ref_img = gr.ImageMask(label='Ref(å‚è€ƒå›¾)', sources=['upload', 'clipboard'], scale=6, transforms=(), layers=False,
                                               placeholder='Upload an image and specify the area you want to edit with a brush')
                        ori_img = gr.Image(label='Ori(åŸå›¾)', scale=4, container=False, interactive=False)

                    def upload_ref(ref, ori):
                        global click_edit_exp
                        if click_edit_exp:
                            original_image = gr.Image()
                            click_edit_exp = False
                        else:
                            original_image = gr.Image(value=ref['background'][..., :3])

                        return [gr.ImageMask(type="numpy"), original_image]


                    def clear_ref(ref, ori):
                        return [gr.ImageMask(), gr.Image(value=None)]
                    ref_img.upload(upload_ref, [ref_img, ori_img], [ref_img, ori_img])
                    ref_img.clear(clear_ref, [ref_img, ori_img], [ref_img, ori_img])
                    with gr.Row():
                        gr.Markdown("")
                        run_edit = gr.Button(value="Run(è¿è¡Œ)!", scale=3, elem_classes='run')
                        gr.Markdown("")

                    def click_exp(ori_img):
                        global click_edit_exp
                        if ori_img is None:
                            click_edit_exp = True
                    gr.Markdown('<span style="color:silver;font-size:15px">Click an example to automatically fill in the parameters.(ç‚¹å‡»ä»¥ä¸‹ç¤ºä¾‹ï¼Œè‡ªåŠ¨å¡«å……å‚æ•°.)</span>')
                    with gr.Tab("English Examples"):
                        defult_font_color = ["No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)", "No Font(ä¸æŒ‡å®šå­—ä½“)","No Font(ä¸æŒ‡å®šå­—ä½“)", 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0, 1)', 'rgba(0, 0, 0,1)']
                        en_exp = gr.Examples(
                            [
                                ['A pile of fruit with words written in the middle', '"UIT"', "example_images/ref13.jpg", "example_images/edit13.png", 4] + defult_font_color +[91498555],
                                ['Characters written in chalk on the blackboard', '"DADDY"', "example_images/ref8.jpg", "example_images/edit8.png", 4] + defult_font_color +[50165756],
                                ['The blackboard with words', '"Here"', "example_images/ref11.jpg", "example_images/edit11.png", 2] + defult_font_color +[15353513],
                                ['A letter picture', '"THER"', "example_images/ref6.jpg", "example_images/edit6.png", 4] + defult_font_color +[38483041],
                                ['A cake with colorful characters', '"EVERYDAY"', "example_images/ref7.jpg", "example_images/edit7.png", 4] + defult_font_color +[8943410],
                                ['photo of clean sandy beach', '" " " "', "example_images/ref16.jpeg", "example_images/edit16.png", 4] + defult_font_color +[85664100],
                            ],
                            [img_prompt, text_prompt, ori_img, ref_img, img_count, font1, font2, font3, font4, color1, color2, color3, color4, seed],
                            examples_per_page=5,
                            label=''
                        )
                        en_exp.dataset.click(click_exp, ori_img)
                    with gr.Tab("ä¸­æ–‡ç¤ºä¾‹"):
                        cn_exp = gr.Examples(
                            [
                                ['ä¸€ä¸ªå°çŒªçš„è¡¨æƒ…åŒ…', '"ä¸‹ç­"', "example_images/ref2.jpg", "example_images/edit2.png", 2] + defult_font_color +[43304008],
                                ['ä¸€ä¸ªä¸­å›½å¤ä»£é“œé’±', 'ä¸Šé¢å†™ç€"ä¹¾" "éš†"', "example_images/ref12.png", "example_images/edit12.png", 4] + defult_font_color +[89159482],
                                ['ä¸€ä¸ªæ¼«ç”»', '" "', "example_images/ref14.png", "example_images/edit14.png", 4] + defult_font_color +[68511317],
                                ['ä¸€ä¸ªé»„è‰²æ ‡å¿—ç‰Œ', '"ä¸è¦" å’Œ "å¤§æ„"', "example_images/ref3.jpg", "example_images/edit3.png", 2] + defult_font_color +[68988613],
                                ['ä¸€ä¸ªé’é“œé¼', '"  ", "  "', "example_images/ref4.jpg", "example_images/edit4.png", 4] + defult_font_color +[71139289],
                                ['ä¸€ä¸ªå»ºç­‘ç‰©å‰é¢çš„å­—æ¯æ ‡ç‰Œ', '" "', "example_images/ref5.jpg", "example_images/edit5.png", 4] + defult_font_color +[50416289],
                            ],
                            [img_prompt, text_prompt, ori_img, ref_img, img_count, font1, font2, font3, font4, color1, color2, color3, color4, seed],
                            examples_per_page=5,
                            label=''
                        )
                        cn_exp.dataset.click(click_exp, ori_img)
    ips = [img_prompt, text_prompt, sort_radio, revise_pos, base_model_path, lora_path_ratio, *select_font_list, *mimic_list, *select_color_list, show_debug, draw_img, ref_img, ori_img, img_count, ddim_steps, image_width, image_height, strength, attnx_scale, font_hollow, cfg_scale, seed, eta, a_prompt, n_prompt]
    run_gen.click(fn=process, inputs=[gr.State('gen')] + ips, outputs=[result_gallery, result_info])
    run_edit.click(fn=process, inputs=[gr.State('edit')] + ips, outputs=[result_gallery, result_info])

block.launch(server_name='0.0.0.0' if os.getenv('GRADIO_LISTEN', '') != '' else "127.0.0.1", share=False)

# 服务器配置详情

**生成时间**: 2026-01-06
**服务器名称**: lenovo
**用途**: AnyText2 深度学习开发与训练

---

## 硬件配置

### CPU (处理器)
- **型号**: Intel(R) Xeon(R) Silver 4310
- **频率**: 2.10GHz
- **核心数**: 24 核 (12 cores × 2 sockets)
- **线程数**: 48 线程 (2 threads per core)
- **架构**: x86_64

### GPU (显卡)
- **数量**: 3 张 NVIDIA GeForce RTX 4090
- **显存**: 每张 24GB (实际可用 23.5GB)
  - GPU 0: 23.5GB
  - GPU 1: 23.5GB
  - GPU 2: 23.5GB
- **总显存**: 70.5GB
- **驱动版本**: 580.95.05

### 内存 (RAM)
- **总内存**: 62GB
- **已使用**: 31GB
- **可用**: 30GB
- **Swap**: 8GB (已使用 2.1GB)

### 磁盘存储
- **总容量**: 7.2TB
- **已使用**: 2.4TB (35%)
- **可用空间**: 4.6TB
- **文件系统**: LVM (Logical Volume Manager)

### 网络与环境
- **操作系统**: Ubuntu 22.04 (Linux 5.15.0-163-generic)
- **内核**: x86_64

---

## 软件环境

### CUDA
- **Driver Version**: 580.95.05 (支持 CUDA 13.0)
- **CUDA Toolkit**: 12.6.20
- **编译器**: nvcc (Built on Fri_Jun_14_16:34:21_PDT_2024)

### Python 环境
- **系统 Python**: 3.12.7 (base 环境)
- **AnyText2 环境**: Python 3.10 (Conda)
- **环境名称**: anytext2
- **环境路径**: /home/zyh/anaconda3/envs/anytext2

### 深度学习框架 (anytext2 环境)
- **PyTorch**: 2.1.0+cu118
- **CUDA Runtime**: 11.8 (兼容 CUDA 12.6)
- **CUDA Available**: ✅ Yes
- **GPU 检测**: 3 GPUs 可用

---

## AnyText2 项目配置

### 项目存储
- **项目路径**: /home/zyh/AnyText2
- **项目总大小**: 215GB
- **数据集**: 200GB (AnyWord-3M)
- **模型文件**: 15GB

### 关键依赖版本
```
PyTorch: 2.1.0+cu118
Gradio: 4.44.1
gradio_client: 1.0.2 (已修复)
modelscope: 1.4.0
transformers: 4.34.1
datasets: 2.14.6
Pillow: 10.4.0
```

### 模型权重
- **主模型**: ./models/iic/cv_anytext2/anytext_v2.0.ckpt
- **配置文件**: ./models_yaml/anytext2_sd15.yaml
- **OCR 权重**: 已嵌入主模型 (456 个 keys)

### 已修复的兼容性问题
1. ✅ PyTorch CUDA 支持 - 从 CPU 版本升级到 2.1.0+cu118
2. ✅ Gradio 版本兼容 - 升级到 4.44.1
3. ✅ gradio_client TypeError - 修复 JSON Schema 布尔值处理
4. ✅ Pillow 10.x API - 替换 getsize() 为 getbbox()
5. ✅ FP16/FP32 混合精度 - 修复注意力计算类型不匹配
6. ✅ 字体选择 None 处理 - 添加 try-except 保护

---

## 性能参数

### 计算能力
- **CPU 理论性能**:
  - 基准频率: 2.10GHz
  - 最大加速: 未启用 Turbo Boost
  - 总计算能力: 48 核心线程

- **GPU 理论性能** (单卡 RTX 4090):
  - CUDA Cores: 16384
  - Tensor Cores: 512 (第四代)
  - 内存带宽: 1,008 GB/s
  - FP32 性能: 82.6 TFLOPS
  - TF32 性能: 165.2 TFLOPS
  - FP16 性能: 330.3 TFLOPS

### 显存分配 (AnyText2 运行时)
- **推理模式 (FP16)**: ~6-8GB/卡
- **训练模式**: 建议 batch_size=3, 需要 ~20GB/卡
- **多卡支持**: ✅ 支持 DataParallel

### I/O 性能
- **存储类型**: 未明确 (建议使用 NVMe SSD)
- **数据加载速度**: 取决于磁盘类型

---

## 当前运行状态

### 服务运行
- **AnyText2 Demo**: ✅ 运行中
- **访问地址**: http://127.0.0.1:7860
- **模式**: FP16 推理模式 (--no_translator)
- **进程 ID**: 动态分配

### 资源占用 (典型值)
- **显存占用**: ~6-8GB/卡 (单卡推理)
- **内存占用**: ~4-8GB
- **CPU 占用**: ~10-20% (推理时)

---

## 网络配置

### 本地访问
- **地址**: http://127.0.0.1:7860
- **端口**: 7860 (默认)

### 远程访问 (如需配置)
修改 demo.py 的 launch 参数:
```python
block.launch(
    server_name="0.0.0.0",
    server_port=7860,
    share=True  # 创建公共隧道链接
)
```

### 防火墙
- 状态: 未明确配置
- 建议开放端口: 7860 (如需远程访问)

---

## 开发环境建议

### 训练配置 (推荐)
- **模式**: 多卡 DataParallel
- **Batch Size**: 3×3=9 (3卡 × batch_size=3)
- **精度**: FP16 (mixed precision)
- **梯度累积**: 2 步
- **学习率**: 2e-5
- **数据集**: AnyWord-3M (200GB)

### 推理配置 (推荐)
- **模式**: 单卡
- **精度**: FP16
- **DDIM Steps**: 20-50
- **CFG Scale**: 7.0-9.0
- **图像尺寸**: 512×512 / 1024×1024

### 优化建议
1. **使用多卡推理**: 修改 demo.py 指定不同 GPU
2. **增加 batch size**: 推理时可增加到 4-8
3. **使用 xformers**: 加速注意力计算 (可选安装)
4. **启用 torch.compile**: PyTorch 2.0+ 编译优化

---

## 备份与维护

### 关键数据位置
- **项目代码**: /home/zyh/AnyText2
- **数据集**: /home/zyh/AnyText2/dataset (200GB)
- **模型权重**: /home/zyh/AnyText2/models (15GB)
- **Conda 环境**: /home/zyh/anaconda3/envs/anytext2

### 定期维护
- **清理缓存**: `conda clean --all`
- **检查磁盘**: `df -h`
- **监控 GPU**: `nvidia-smi` 或 `watch -n 1 nvidia-smi`
- **日志检查**: /tmp/demo_working.log

### 环境重建脚本
保存以下命令为 `rebuild_env.sh`:
```bash
#!/bin/bash
conda create -n anytext2 python=3.10 -y
conda activate anytext2
pip install torch==2.1.0 torchvision==0.16.0 \
    --index-url https://download.pytorch.org/whl/cu118
pip install gradio==4.44.1
pip install modelscope==1.4.0
pip install transformers==4.34.1
pip install datasets==2.14.6
pip install opencv-python pillow einops basicsr safetensors
pip install pytorch-lightning==1.5.0 omegaconf
pip install open_clip_torch==2.7.0
```

---

## 性能基准测试 (预期)

### AnyText2 推理速度
- **512×512, 20 steps**: ~3-5 秒/图 (单卡 FP16)
- **1024×1024, 50 steps**: ~15-20 秒/图 (单卡 FP16)
- **Batch=4, 512×512**: ~12-15 秒/4图

### 训练速度 (预期)
- **Batch=9 (3卡×3)**: ~1.5-2.0 it/s
- **每个 epoch**: ~4-6 小时 (AnyWord-3M 全量数据)

---

## 联系信息

- **用户**: zyh@lenovo
- **项目路径**: /home/zyh/AnyText2
- **文档位置**:
  - 项目说明: /home/zyh/AnyText2/CLAUDE.md
  - 中文文档: /home/zyh/AnyText2/AnyText2_项目全面解析.md
  - 问题排查: /home/zyh/AnyText2/Demo启动完整问题排查与解决方案.md

---

## 更新日志

- **2026-01-06**: 初始配置记录
- **环境**: anytext2 conda 环境
- **状态**: ✅ 所有功能正常运行

---

**总配置价值**: 约 15-20 万人民币 (高配置深度学习服务器)
**适用场景**: 大规模深度学习训练、文本生成与图像合成、AI 模型开发
